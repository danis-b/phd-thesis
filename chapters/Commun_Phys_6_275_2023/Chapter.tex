\openleft%
\chapter{Many-body quantum sign structures as non-glassy Ising models}\label{ch:cp23}

{\small The non-trivial phase structure of the eigenstates of many-body quantum systems severely limits the applicability of quantum Monte Carlo, variational, and machine learning methods. Here, we study real-valued signful ground-state wave functions of frustrated quantum spin systems and, assuming that the tasks of finding wave function amplitudes and signs can be separated, show that the signs can be easily bootstrapped from the amplitudes. We map the problem of finding the sign structure to an auxiliary classical Ising model defined on a subset of the Hilbert space basis. We show that the Ising model does not exhibit significant frustrations even for highly frustrated parental quantum systems, and is solvable with a fully deterministic $O(K\log K)$-time combinatorial algorithm (where $K$ is the Ising model size). Given the ground state amplitudes, we reconstruct the signs of the ground states of several frustrated quantum models, thereby revealing the hidden simplicity of many-body sign structures.}

\AdaptedFrom{https://doi.org/10.1038/s42005-023-01388-6}{T. Westerhout, M. I. Katsnelson, \& A. A. Bagrov\\Communications Physics, 6(1), 275 (2023).}
\clearpage

\section{Introduction}

\lettrine[lines=3]{T}{he} concept of phase of a quantum state is the main distinctive feature that makes the realm of quantum physics so different from the classical statistical mechanics~\cite{quantum_phase}. Although it is unobservant itself, the wave function phase structure stands behind such phenomena as quantum interference~\cite{interference}, Anderson localization~\cite{localization}, many-body coherence~\cite{coherence}, and the Aharonov-Bohm nonlocality~\cite{Aharonov-Bohm,olariu}. In many-body systems, the nodal surface,---the surface of zeros of the wave function,---encodes important information about the overall phase structure. It is intimately connected to the entanglement properties of quantum states~\cite{Kaplis}. For example, it has been demonstrated that real-valued non-negative wave functions cannot support extensive entanglement entropy scaling~\cite{Grover}. Vice versa, long-range entangled quantum critical states are conjectured to have highly non-trivial (and even fractal) nodal surfaces~\cite{fractals} implying that the phase is a physically relevant property of quantum systems rather than a mere numerical abstraction.

On top of causing interesting and counter-intuitive emergent phenomena, non-trivial phase structures make studying interacting many-body systems notoriously difficult, especially when dealing with frustrations~\cite{frustrations} or finite-density fermionic matter~\cite{finite_density}. Quantum Monte Carlo (QMC) algorithms suffer from the Sign Problem that spoils the sampling convergence~\cite{sign_problem} and represents the main barrier preventing researchers from routinely simulating generic quantum systems with classical hardware. Resorting to variational wave functions, such as variational Monte Carlo ans\"atze~\cite{vmc}, tensor networks~\cite{Orus}, or neural-network quantum states (NQS)~\cite{Carleo}, is one of the standard ways of getting around the Sign Problem. For instance, convolutional neural networks have been successfully applied in combination with determinant QMC to identify phase transitions in many-body quantum systems suffering from sever forms of Sign Problem~\cite{Trebst}. However, for the ground state search, optimizing the phases of many-body variational quantum states is a non-trivial problem either~\cite{sign_generalization,Szabo_2020_Neural_network} due to the excessive complexity in expressing phases~\cite{kastoryano} as well as the inability of the variational ansatz to generalize them from a limited sampled subset of the Hilbert space~\cite{sign_generalization}. 

On the other hand, if one is lucky enough to have a good approximation for the nodal surface or the phase structure of a quantum state, further analysis of the correlation effects becomes algorithmically straightforward~\cite{Ceperley}. This principle underlies the fixed-node diffusion Monte Carlo~\cite{fixed_node} and path integral Monte Carlo algorithms~\cite{Ceperley_path}. Using a proper nodal surface as a starting point of variational optimization schemes helps achieve good results for diverse physical systems such as spin liquids~\cite{spin_liquids, astrakhantsev2021}, strongly correlated superconductors~\cite{Imada_SC}, and strange metals~\cite{strange_metals}. This is one of the main reasons for success of some widely used variational ans\"atze such as the Slater-Jastrow~\cite{Slater_Jastrow_1, Slater_Jastrow_2} or the Gutzwiller-projected wave functions \cite{Gutzwiller, Nomura, ferrari2019neural}.

The utmost practical importance of retrieving phases of many-body quantum states requires a deeper understanding of the Sign Problem and related structural properties of nodal surfaces. Computational complexity of the Sign Problem has been analyzed, and it was shown that, in its most general form, this problem is nondeterministic polynomially (NP) hard~\cite{NP_Troyer}. Its fundamental origins have been investigated and, within the framework of path integral QMC, have been related to topological properties of imaginary time evolution encoded in the analogue of the Aharonov-Anandan phase~\cite{Soluyanov}. Analytical insights into the geometry of the nodal surfaces of few-electron systems have also been obtained~\cite{nodal1, nodal2}.

Despite the generally high formal complexity of the Sign Problem, in each particular case, bypassing it could turn out to be an easy or a very difficult task. Hence, it is natural to seek an approach for assessing the practical complexity of phase structures of generic many-body systems. Here, we develop an alternative formal perspective on the problem of the reconstruction of many-body phase structures and relate its complexity to the complexity of combinatorial optimization of classical Ising models. For that, we reverse the perspective of fixed-node approaches and ask a complementary question: if the knowledge of the phase (or nodal) structure helps the optimization algorithm so much, could the knowledge of the wave function amplitudes be used to efficiently reconstruct its phases? Should this be true, amplitudes and phases could potentially be bootstrapped from each other in an algorithm such as variational Monte Carlo, where it has been shown that separating the tasks of optimizing amplitudes and phases leads to more accurate results~\cite{astrakhantsev2021} (originally, the idea of separating amplitude and sign structures was introduced in \cite{torlai2018neural}).

In this paper, we address the problem of reconstructing many-body sign structures of ground states of time-reversal symmetric Hamiltonians. This class of systems embraces Heisenberg magnets with arbitrary couplings and types of anisotropy as well as Hubbard and extended Hubbard models on generic lattices, thus covering a plethora of phenomenologically important models. Specifically, we focus on several spin-$\frac12$ frustrated Heisenberg models. We show that, if amplitudes of a ground-state wave function are known, the sign structure can be reconstructed efficiently and with a high degree of accuracy. This can be done by mapping the task of sign structure optimization onto an auxiliary classical Ising model that is defined on the Hilbert space basis. We show that this auxiliary model is much less frustrated than the original quantum model and can be solved with a fast greedy algorithm. Although this paper focuses mainly on the specific problem of reconstructing the sign structures from amplitudes and leaves the task of implementing a complete variational ground state optimization algorithm for future studies, we demonstrate that the signs of the wave function coefficients can be obtained even if the amplitudes are known only up to a large error, and we provide a precise description of the complete variational algorithm in the Supplemental Information.

\section{Results}\label{sec:Ising}

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.7\textwidth]{handmade/cartoon_ising.pdf}
	\caption{\label{fig:sign_ising}Cartoon illustration of the auxiliary classical Ising model for signs. For the ground state of a quantum lattice model a), the Hilbert space basis vectors with non-zero amplitudes b) become sites of the classical Ising model c). Couplings $\mathcal{J}$ between classical spins representing signs are defined by matrix elements of the quantum Hamiltonian and amplitudes of the basis vectors.}
\end{figure}

Consider a real-valued quantum lattice Hamiltonian $\hat{H}$.  Its ground state can be expressed in the computational basis as
\begin{equation}
|\psi \rangle = \sum\limits_{i=1}^D \psi_i \, |i\rangle = \sum\limits_{i=1}^D \mathcal{S}_i |\psi_i| \,| i \rangle \,,
\label{eq:quantum_gs}
\end{equation}
where $\psi_i$ are real-valued, $\mathcal{S}_i = \mathrm{sign}(\psi_i)$, and $D$ denotes the Hilbert space dimension. Energy of the ground state is given by the expectation value of $\hat{H}$:
\begin{equation}
    E = \langle \psi | \hat{H} | \psi \rangle = \sum\limits_{i,j = 1}^{D} \langle i | \hat{H} | j \rangle |\psi_i| |\psi_j| \, \mathcal{S}_i \mathcal{S}_j \,. \label{eq:gs_energy}
\end{equation}

Suppose, that the amplitudes $\{|\psi_i|\}_i$ are known, and the signs $\{\mathcal{S}_i\}_i$ are to be determined. Eq.~\eqref{eq:gs_energy} can be interpreted as the energy of a classical Ising model defined on the set of basis vectors of the Hilbert space, Fig. \ref{fig:sign_ising}:
\begin{equation}
    \mathcal{H} = \sum\limits_{i,j = 1}^D \mathcal{J}_{i,j} \mathcal{S}_i \mathcal{S}_j\,, \text{ where } \mathcal{J}_{i,j} = |\psi_i||\psi_j| \langle i | \hat{H} | j \rangle \,. \label{eq:Ising}
\end{equation}
The signs are binary variables, and the ground state sign structure is the ground state of the Ising model $\mathcal{H}$. The Ising model is defined on the graph with topology determined by the quantum Hamiltonian $\hat{H}$ (when viewed as an adjacency matrix).

This simple mapping allows one to think about the complexity of quantum many-body sign structures in terms of the optimization complexity of classical spin models. What are the conditions on $\mathcal{J}_{i,j}$ to have a reachable global minimum of Eq.~\eqref{eq:Ising}? What is the difference between the auxiliary sign Ising models of simple and highly-frustrated quantum systems? Do sign structures exhibit glassy behavior~\cite{glasses}?

As an illustration, let us start by considering an unfrustrated quantum Hamiltonian $\hat{H}$ such as the Heisenberg model on a square lattice with nearest-neighbor interactions only. The absence of frustrations in the quantum model implies the absence of frustrations in the induced Ising model. A proof of this statement for the Heisenberg model on an arbitrary lattice with or without anisotropy is provided in Supplemental Information, but we believe that the statement can be generalized to other types of interactions. When the Ising model is unfrustrated, the sign structure can be obtained trivially with a greedy algorithm processing the graph in a depth-first or breadth-first manner~\cite{CLRS}. Indeed, if some basis vector $|i\rangle$ has sign $\mathcal{S}_i$, the sign of its neighbor $|j\rangle$ is simply given by $\mathcal{S}_j = - \mathcal{S}_i \cdot \mbox{sign}(\langle i | \hat{H} |j\rangle)$.

Frustrated quantum systems are less trivial. Nevertheless, we will show that, somewhat counter-intuitively, the auxiliary Ising model has a simple optimization landscape even when the parental quantum model is frustrated and has a complicated sign structure that is hard to obtain with traditional algorithms. To this end, we first employ combinatorial optimization in a form of Simulated Annealing (SA) algorithm~\cite{SA}, and then show that good results can be obtained even with an $\mathcal{O}(K \log K)$ greedy algorithm, where $K$ is the size of the Ising model. Combinatorial optimization has been employed earlier in an attempt to learn the sign structures of some frustrated magnets~\cite{Nikita_sign}. However, in that paper, genetic optimization was used for the training of a neural network whereas here we directly optimize the sign structure.

In the following, we will demonstrate that

\begin{enumerate}[topsep=0pt,noitemsep]
    \item For relatively small quantum systems, SA finds exact ground states of the auxiliary Ising models with high probability, and the greedy algorithm even manages to find them in a deterministic way. The Hilbert space dimension is still large enough to claim that classical glasses of such size are not amenable to global optimization.
    \item For larger quantum systems where global optimization is unfeasible, local optimization on small connected clusters of the Ising models yields a very good approximation to the global solution.
\end{enumerate}
Together, these two findings indicate that the auxiliary Ising model is frustrated very mildly, and that the complexity of the sign structure identification is far below that of finding the ground state of a classical glass, at least in a number of non-trivial physically relevant cases.

\subsection{Small quantum systems}

\SideFigure{0.5\textwidth}{0pt}{0.5\textwidth}{\subimport{assets}{Figure_2.pgf}%
}{Quality of simulated annealing optimization of the sign structure for small quantum models. We show the probability of convergence to at least $99.5\%$ accuracy as a function of the number of sweeps. Solid points are the numerical data, and shaded regions indicate the uncertainty (plus-minus two standard deviations). Probability of convergence is obtained by running the simulated annealing algorithm 1024 times and counting the number of converged runs. To estimate the uncertainties, we repeat the simulation 10 times. So in total, 10240 simulated annealing runs were performed to obtain each point. For frustrated models with regular lattice geometries, the probability of convergence approaches $1$ when the number of sweeps is increased. For the random fully-connected model, it depends on the concrete realization of couplings, but still exceed $50\%$.%
}{fig:small_models}
% \begin{figure}
%     \centering
%     \subimport{./assets}{Figure_2.pgf}
%     \includegraphics[width=0.5\textwidth]{./assets_revised/annealing_on_small_systems.pdf}
    
%     \caption{\label{fig:small_models}\textbf{Quality of simulated annealing optimization of the sign structure for small quantum models.} We show the probability of convergence to at least $99.5\%$ accuracy as a function of the number of sweeps. Solid points are the numerical data, and shaded regions indicate the uncertainty (plus-minus two standard deviations). Probability of convergence is obtained by running the simulated annealing algorithm 1024 times and counting the number of converged runs. To estimate the uncertainties, we repeat the simulation 10 times. So in total, 10240 simulated annealing runs were performed to obtain each point. For frustrated models with regular lattice geometries, the probability of convergence approaches $1$ when the number of sweeps is increased. For the random fully-connected model, it depends on the concrete realization of couplings, but still exceed $50\%$.}
% \end{figure}

Let us start by considering a few small clusters: antiferromagnetic Heisenberg model on 16 and 18-site Kagome lattices, $J_1$-$J_2$ model on 16-site square lattice with the nearest-neighbour ($J_1$) and next-nearest-neighbour ($J_2$) interactions, and 16-site Heisenberg model with random all-to-all exchange interaction. For the $J_1$-$J_2$ model, we focus on the case when $J_2 = 0.55 J_1$ which is considered to be one of the most difficult points for variational algorithms. For the random Heisenberg model we draw exchange couplings $J_{i,j}$ from the Gaussian distribution with zero mean and variance 1. More details about the systems are provided in Supplemental Information.

These models are easily solvable with the exact diagonalization (ED) method, and their ground states belong to the sectors of zero magnetization. The resulting dimensions of the auxiliary Ising models are then
\begin{equation*}
    D = \binom{N}{N/2} 
      = \left\{
      \begin{aligned}
         &12870\mbox{, when }N=16, \\
         &48620\mbox{, when }N=18
      \end{aligned}
      \right.
\end{equation*}
If these sign Ising models had glassy energy landscapes, the task of finding their ground states would be far beyond the capacity of SA or devices such as D-Wave quantum annealers (Advantage\texttrademark\ QPU, for instance, can handle more than 5000 variables, but is limited to a special connectivity-15 graph~\cite{boothby2020next}).

In Fig.~\ref{fig:small_models} we show the probability of convergence for the Simulated Annealing algorithm (parameters of the algorithms are provided in Supplemental Information). We say that the algorithm has converged if it has reached at least $99.5\%$ accuracy. This threshold is chosen, on one hand, to avoid problems arising from numerical inaccuracies---some basis vectors have zero amplitudes up to machine precision, and their signs cannot be determined faithfully. On the other hand, the threshold is still high enough to consider the results exact for all practical purposes.

\begin{figure}
    \centering
    \subimport{assets}{Figure_3.pgf}%
    % \includegraphics[width=0.5\textwidth]{./assets_revised/Figure_3.pdf}
    \caption{Distribution of the Ising model couplings. a) Sorted distribution of couplings of the Ising models corresponding to ground states of the studied quantum systems. In the logarithmic scale it is evident that large couplings comprise only a small fraction within the whole graph and, hence, could be sparsely distributed. b) Histogram of the probability that a coupling of given magnitude is not frustrated (in other words, the locally optimal state of the corresponding two spins is compatible with the global solution). Larger couplings are likely not frustrated, which underlies the success of simple optimization algorithms.}
    \label{fig:coupling_distribution}
\end{figure}

It turns out that for the Heisenberg model on the Kagome lattices and for the $J_1$-$J_2$ model on the square lattice, the algorithm almost always converges if the number of Simulated Annealing sweeps is at least $50000$. For the random all-to-all connected models, the chance of finding the exact sign structure depends on the particular realization, but still exceeds $50\%$ when the number of sweeps is at least $10000$. Hence, repeating SA 20 times (which can be done in parallel) with $10000$ sweeps ensures that we find the ground state with more than $99.9999\%$ probability. These results should be compared to Fig.~4 of Ref.~\cite{heim2015quantum} where SA is applied to spin glasses with $6400$ spins, and even after $10^8$ Monte Carlo steps, the residual energy is still above $10^{-3}$. Our experiments thus show that, for rather generic and even random bi-local frustrated quantum systems, the sign optimization landscape is very mildly frustrated.

To understand the origin of such non-glassy behavior, it is instructive to take a look at the distributions of couplings of the auxiliary Ising models. They arises from the distributions of amplitudes $|\psi_i|$ of the corresponding quantum Hamiltonian ground states, which are often strongly peaked with a relatively small fraction of large amplitudes. In turn, the distributions of $|\mathcal{J}_{i,j}|$ are also peaked as shown in Fig.~\ref{fig:coupling_distribution}a. As a result, the model landscapes are likely dominated by a moderate number of strong couplings that are sparsely distributed across the Ising model graphs and do not strongly compete with each other. If it is truly the case, there is a possibility that a nearly optimal solution of the Ising model can be obtained even without full combinatorial optimization. As can be seen from Fig.~\ref{fig:coupling_distribution}~b), the optimal sign structure does not induce frustration on most links with large values of $|\mathcal{J}_{i,j}|$. To further explore this, we attempt to reproduce the exact solution by using a simple greedy algorithm that goes through each of the Ising spins only once and performs local optimization. The algorithm processes couplings in the decreasing order of $|\mathcal{J}_{i,j}|$ and relies on simple heuristics to minimize frustrations. A detailed description of the algorithm is provided in the Methods section. Results of executing this algorithm on the 16- and 18-spin models are given in Tab.~\ref{tab:cp23:greedy}. One can see that for the $J_1$-$J_2$ model, one of the Kagome lattices, and two instances of the all-to-all connected model with random couplings, our completely deterministic local optimization procedure gives exact results, and for the remaining models---imperfect, but high quality solutions. In contrast with SA, this algorithm is immanently non-stochastic and always produces the same solution, so there is no need to do many sweeps or run the algorithm a number of times to collect statistics. This indicates that frustrations in the auxiliary Ising models truly are almost negligible.

\normalcaptionwidth
\captionwidth{\linewidth}
\begin{table}
  \centering
  \begin{minipage}[t]{0.5\textwidth}%
    \vspace{0pt}\fontsize{8pt}{10pt}\selectfont%
    \centering%
    \begin{tblr}{|l|c|c|} 
     \hline
     System & Accuracy & Overlap \\
     \hline
     16-site $J_1$-$J_2$ model & 1.0 & 1.0  \\ 
     16-site Kagome lattice & 1.0 & 1.0  \\
     18-site Kagome lattice & 0.998 & 1.0  \\
     16-site random, \textnumero 1 & 1.0 & 1.0  \\
     16-site random, \textnumero 2 & 1.0 & 1.0  \\
     16-site random, \textnumero 3 & 0.945 & 0.885  \\
     \hline
    \end{tblr}
  \end{minipage}
  \begin{minipage}[t]{0.35\textwidth}%
    \centering%
    \vspace{5pt}%
    \innerTableCaption{Results of the greedy optimization for small quantum systems. The simulations are fully deterministic. Accuracy and overlap are computed on the full Hilbert space.}
    \label{tab:cp23:greedy}
  \end{minipage}%
  \vspace{-0.2cm}
\end{table}
\changecaptionwidth
\captionwidth{0.9\linewidth}

% \begin{table}[h]
%   \centering
%   \fontsize{8pt}{11pt}\selectfont
%   \begin{tblr}{|c|c|c|c|c|c|c|}
%     \hline
%     Package & Spins & {Generic \\ $H$} & {Matrix-\\free\\repr.} & {Lattice\\ symm.} & {Distributed-\\memory\\parallelism} & {SLoC\\(excl. tests)} \\
% 	\hline
% 	LS~\cite{Westerhout2021latti} & \cmark & \cmark & \cmark & \cmark & \cmark & 8500 \\
% 	SPINPACK~\cite{Schule2017Spinpack} & \cmark & \xmark & \cmark & \cmark & \cmark & 26000 \\
% 	QuSpin~\cite{Weinbe2017QuspinAPytho,Weinbe2019QuspinAPytho} & {\cmark} & {\cmark} & {\cmark} & {\cmark} & \xmark & 26000 \\
% 	quantum\_basis~\cite{Wang2023QuantumBasis} & \cmark & \xmark & \xmark & \cmark & \xmark & 12500 \\
% 	Hydra~\cite{Shackl2022HydraHighPer} & \cmark & \cmark & \cmark & \SetCell[c=2]{c} either one, but not both & & 18000 \\
% 	libcommute~\cite{Kriven2022LibcommutePyco} & \cmark & \cmark & \cmark & \xmark & \xmark & 4500 \\
% 	H$\Phi$~\cite{Kawamura2017quant} & \cmark & \cmark & \cmark & \xmark & \cmark & 29000 \\
% 	Pomerol~\cite{Antipo2015Pomerol} & \xmark & \cmark & \xmark & \xmark & \cmark & 5000 \\
% 	EDLib~\cite{Iskako2018ExactDiagonali} & \xmark & \xmark & \xmark & \xmark & \cmark & 4000 \\
% 	EDIpack~\cite{Amaricci2022edipa} & \xmark & \xmark & \xmark & \xmark & \cmark & 11000 \\
% 	\hline
%   \end{tblr}
%   \vspace{0.2cm}
%   \caption{Feature matrix of various open source exact diagonalization packages. The column ``Spins'' indicates whether the package supports spin-1/2 particles. The column ``Generic $H$'' indicates whether custom user-defined Hamiltonians are supported by the package and serves as an indication of ease of use and extensibility. ``SLoC'' stands for Software Lines of Code and serves as a very rough estimate of the complexity of the codebase. Other columns are discussed in the main text.}
%   \label{tbl:ls23:feature-matrix}
% \end{table*}

Importantly, this sign structure is not only retrievable with high accuracy in $\mathcal{O}(K \log K)$ time (where $K$ is the number of Ising spins), but can be shown to be robust to noise in the amplitudes of the wave function. To this end, we corrupt amplitudes of the ground state by adding noise to the logarithms of the amplitudes:
\begin{equation}
    \log \left|\psi^\mathrm{corrupt}_i\right| \equiv \log \left|\psi^\mathrm{exact}_i\right| + \epsilon_i, \,\,\, \epsilon_i \sim \mbox{Uniform}(-\epsilon, \epsilon ), 
\end{equation}
and vary the maximal noise amplitude $\epsilon$. To gauge the overall magnitude of noise, we introduce a measure that we call amplitude overlap between the exact and the corrupted states:
\begin{equation}
    O^\mathcal{A} \equiv \sum_i |\psi^\mathrm{exact}_i|\cdot |\psi^\mathrm{corrupt}_i|,
\end{equation}
where both the exact and corrupted wave functions are normalized. Without the noise $\mathcal{O}^\mathcal{A} = 1$, and smaller values of the amplitude overlap correspond to higher levels of noise. In particular, if $\psi^\mathrm{corrupt}_i$ are fully random and bear no information about the true solution, the amplitude overlap approaches $0.3$--$0.5$ for the models from Tab.~\ref{tab:cp23:greedy}. Results for small regular lattices are shown in Fig.~\ref{fig:noise_small}, where quality of the retrieved sign structure is measured by the sign overlap that is defined as
\begin{equation}
    O^\mathcal{S} \equiv  \sum_i |\psi^\mathrm{exact}_i|^2 \mathcal{S}_i^\mathrm{exact}\mathcal{S}_i^\mathrm{retrieved}
\end{equation}

\SideFigure{0.55\textwidth}{0pt}{0.45\textwidth}{\subimport{assets}{Figure_4.pgf}%
}{Robustness of the retrieved sign structure. Quality of the sign structure measured by the sign overlap $O^\mathcal{S}$ as a function of the quality of amplitudes measured by the amplitude overlap $O^\mathcal{A}$. For regular lattices, $O^\mathcal{S}$ stays above $0.9$ as long as $O^\mathcal{A}\gtrsim 0.8$. Solid points are median values after running the optimization for a 100 times with a given $\epsilon$. Shades depict interquartile ranges.%
}{fig:noise_small}
% \begin{figure}[t]
%     \centering

%     \includegraphics[width=0.5\textwidth]{./assets_revised/amplitude_vs_sign_overlap.pdf}
%     \caption{\label{fig:noise_small}\textbf{Robustness of the retrieved sign structure.} Quality of the sign structure measured by the sign overlap $O^\mathcal{S}$ as a function of the quality of amplitudes measured by the amplitude overlap $O^\mathcal{A}$. For regular lattices, $O^\mathcal{S}$ stays above $0.9$ as long as $O^\mathcal{A}\gtrsim 0.8$. Solid points are median values after running the optimization for a 100 times with a given $\epsilon$. Shades depict interquartile ranges.}
% \end{figure}

\noindent One can see that the sign structure remains very close to the exact one for $O^\mathcal{A} > 0.8$. For example, for the 16-site Kagome lattice, $O^\mathcal{A} \approx 0.8$ corresponds to $\epsilon \approx 1.45$. The maximal amplitude of the exact ground state is $\max_i |\psi^\mathrm{exact}_i| = 0.0924$, and its corrupted values fall into the range $[0.02, 0.4]$. At first glance, it seems unbelievable that such extreme deformations of amplitudes have mild effect on the sign structure. A possible explanation of this phenomenon is that, due to the peaked nature of the distribution of amplitudes, even strong noise in the amplitudes does not significantly change their order: if $|\psi^\mathrm{exact}_i| \gg |\psi^\mathrm{exact}_j|$, their corrupted counterparts would likely still satisfy $|\psi^\mathrm{corrupt}_i| > |\psi^\mathrm{corrupt}_j|$. The reconstructed sign structure changes very little if this order is not severely altered, irrespective of the concrete values of amplitudes. For random all-to-all connected lattices, the robustness of the sign structure is less striking, but still pronounced.


\subsection{Finding sign structures of large quantum systems}

In the real cases of interest, the Hilbert space dimension would be too large to perform optimization of signs globally on the full basis. Hence, we need to make sure that it is possible to find the sign structure via local optimization on a subset of the basis. Given the efficiency of the greedy algorithm in the case of small systems, we use it for all numerical experiments in this section and provide some results of executing SA in Supplemental Information.

Let $\mathcal{C}$ be a connected subset of the basis. Ising spins within $\mathcal{C}$ are connected to each other and to ``external'' spins associated with Hilbert space vectors outside of $\mathcal{C}$. The Ising Hamiltonian \eqref{eq:Ising} can then be split into three parts
\begin{equation}
    \mathcal{H} = \sum\limits_{i,j \in \mathcal{C}} \mathcal{J}_{ij} \mathcal{S}_i \mathcal{S}_j + \sum\limits_{n \in \partial \mathcal{C}} \mathcal{S}_n\sum\limits_{k \notin \mathcal{C}} \mathcal{J}_{nk} \mathcal{S}_k + \text{const},
\end{equation}
where $\partial C$ denotes the spins in $\mathcal{C}$ that have at least one external connection. The energy contribution from the connections not involving $\mathcal{C}$ is treated as a constant. If the greedy algorithm is used to perform the optimization on $\mathcal{C}$, it does not change the state of spins outside of the subset, $\mathcal{S}_k, \,\, k \notin \mathcal{C}$, and they can be regarded as external magnetic fields $h_n=\sum\limits_{k \notin \mathcal{C}} \mathcal{J}_{nk} S_k$. If $h_n$ are known, the optimization problem can be solved exactly when $\mathcal{C}$ has a reasonable size (up to a few million elements). However, in reality, the states of the spins outside of $\mathcal{C}$ are unknown, and one needs to make some assumptions about them. The simplest way to proceed is to impose $h_n=0$ and optimize the signs in $\mathcal{C}$ by taking into account just the internal connections. This approximation is valid only if the cumulative strength of the internal connections is much higher than that of the external fields.

\SideFigure{0.45\textwidth}{0.0\textwidth}{0.45\textwidth}{\includegraphics[width=0.9\columnwidth]{handmade/subsystem_new.pdf}%
}{The Hamiltonian extension idea. We start with a connected cluster $\mathcal{C}$ of Ising spins. To obtain its extension $\mathcal{C}^{(1)}$, we additionally include all spins that have at least one connection with $\mathcal{C}$. These spins and the corresponding connections are highlighted in red.%
}{fig:extension}

This property can be ensured with a simple trick. Spins $\mathcal{S}_i$ and $\mathcal{S}_j$ of the classical Ising model are connected if the corresponding quantum Hamiltonian matrix element is nonzero: $\langle i | H | j \rangle = \mathcal{J}_{ij} \neq 0$. One can construct a Hamiltonian extension $\mathcal{C}^{(1)}$ of the cluster $\mathcal{C}$ by adding all the external sites $\mathcal{S}_k \notin \mathcal{C}$ such that $\mathcal{J}_{kj} \neq 0$, for $\mathcal{S}_j \in \partial \mathcal{C}$.  That way, each spin $\mathcal{S}_j$ that previously resided on the boundary $\partial \mathcal{C}$ now belongs to the bulk. Fig.~\ref{fig:extension} illustrates this procedure. Higher order extensions $\mathcal{C}^{(i)}$ can be obtained similarly. After two or three steps, one obtains a large cluster that is dominated by internal connections, and $h_n$ can be safely neglected when running combinatorial/greedy optimization on the extended cluster. The original spins $\mathcal{C}$ lie deep inside the larger cluster, and their signs can be reconstructed with good accuracy. It should be noted that, due to the sparsity of the quantum Hamiltonian, these extensions would be of much smaller size than the dimension of the Hilbert space even in the case of all-to-all connected Heisenberg model (see the bottom panel of Fig.~\ref{fig:overlap_and_clusters}).

To test the above procedure, we consider the ground states of the Heisenberg model on the 36-site Kagome lattice \cite{kagome36} and 32-site pyrochlore lattice (the $2\times 2\times 2$ configuration) \cite{astrakhantsev2021}, and one realization of the random Heisenberg model with all-to-all connections on 32 sites. All these models can still be solved with ED, but the corresponding Hilbert spaces become large enough to serve as a test bed for studying the quality of the greedy optimization on smaller subsets. For the random Heisenberg model, the only symmetry we use is $U(1)$ (magnetization conservation), and the Hilbert space dimension of the zero-magnetization sector is $D = \binom{32}{16} \approx 6\cdot 10^8$. For the pyrochlore and Kagome lattices, lattice symmetries can be taken into account, and the corresponding Hilbert space dimensions are approximately $8 \cdot 10^5$ and $3 \cdot 10^7$, correspondingly.

For each ground state, we sample random connected clusters $\mathcal{C}$ of various sizes. For each of them, we construct extensions of the first and second orders, and run greedy optimization on both the original $\mathcal{C}$ and the extended $\mathcal{C}^{(i)}$ clusters ignoring the external fields. The quality of the obtained sign structure is measured by the normalized sign overlap between the variational wave function (with signs from the greedy optimization and amplitudes from ED) and the true one (with both signs and amplitudes from ED), which we compute on the basis states belonging to $\mathcal{C}$:
\begin{equation}
	O^\mathcal{S}_\mathcal{C} = \frac{1}{\sum_{i \in \mathcal{C}} |\psi_i|^2}
	\cdot \sum\limits_{i \in \mathcal{C}}
            \overbrace{|\psi_i|\mathcal{S}_i}^\text{variational}
            \cdot \underbrace{\psi_i}_\text{exact} \,,
\end{equation}
where $\mathcal{S}_i$ are obtained from the greedy optimization.

\begin{figure*}[t]
    \centering
    \subimport{assets}{Figure_6.pgf}
    % \includegraphics[width=0.95\textwidth]{./assets_revised/Figure_8.pdf}
    \caption{\label{fig:overlap_and_clusters}\textbf{Quality of the sign structures on random small connected clusters from the greedy algorithm.} The results are shown for \textbf{a} the 32-site pyrochlore lattice, \textbf{b} 36-site Kagome lattice, and \textbf{c} 32-site all-to-all connected model with random couplings. 
    The top panel shows the distribution (or the probability density function, PDF) of clusters as a function of the resulting normalized sign overlap $O^\mathcal{S}_\mathcal{C}$. We run the greedy algorithm on the original cluster $\mathcal{C}$ as well as on its Hamiltonian extensions $\mathcal{C}^{(1)}$ and $\mathcal{C}^{(2)}$. The insets show complementary cumulative distribution functions (CCDF) showing the overall probability to obtain normalized sign overlap higher than a chosen value. The bottom panel shows how sizes of the clusters and their extensions are distributed. Subfigure \textbf{a} is plotted using $100\,000$ data points, subfigures \textbf{b} and \textbf{c}---using $80\,000$ data points.}
\end{figure*}

In Fig.~\ref{fig:overlap_and_clusters}, we show the quality of the greedy optimization for \textbf{a} the 32-site pyrochlore lattice, \textbf{b} the 36-site Kagome lattice, and \textbf{c} the 32-site random Heisenberg model. The overlap $O^\mathcal{S}_\mathcal{C}$ depends on the extension order, and, as can be seen from the complementary cumulative distribution functions, constructing the second order extension appears sufficient to reach $O^\mathcal{S}_\mathcal{C} \simeq 0.9$ with a chance of about 70\% on all systems. Clusters $\mathcal{C}$ were sampled in a way to ensure that their sizes are logarithmically distributed in the range $[50,1000]$, which is a typical range of sizes that one would encounter in the context of variational Monte Carlo as described in Supplemental Information. There, we also analyze how the quality of the obtained sign structures is affected by noise in amplitudes. Just as for the smaller systems, the algorithm is robust to noise (Supplemental Information), but for optimal results, the optimization should be carried out on the third-order extensions ${\mathcal C}^{(3)}$.

Fig.~\ref{fig:pdf_sizes} shows that there is no real dependence of the quality of optimization on the original cluster size: probabilities of having the normalized sign overlap $O^\mathcal{S}_\mathcal{C} \gtrsim 0.9$ are approximately the same for the clusters of sizes $[50, 106]$, $[106, 224]$, $[224, 473]$, and $[473, 1000]$. This, together with the fact that $\mathcal{C}^{(2)}$ extensions are much smaller than the Hilbert space basis, Fig. \ref{fig:overlap_and_clusters} (bottom panel), tells us that the result of local cluster optimization is compatible with the global sign structure. In other words, the Ising model is not glassy. 

\SideFigure{0.5\textwidth}{0pt}{0.4\textwidth}{\subimport{assets}{Figure_7.pgf}%
}{Sign structure quality and the cluster $\mathcal{C}$ size do not correlate. Complementary cumulative distribution functions (CCDF) of sign overlaps for different ranges of the original cluster $\mathcal{C}$ sizes (as shown in the legend) for the 36-spin Kagome model. Similarity of the curves clearly indicates that correlation between quality of optimization and cluster sizes is insignificant.%
}{fig:pdf_sizes}

\section{Discussion}

In this paper, we have suggested a way of analyzing the sign structure of a many-body quantum system ground state through the lens of an auxiliary classical Ising model. The Ising model is defined by the quantum Hamiltonian and the amplitudes of the ground state. We have shown that such models turn out to be mildly frustrated and can be easily solved with the help of standard combinatorial optimization algorithms such as Simulated Annealing or even a simple greedy algorithm.

A naturally arising question is how having a close-to-optimal sign structure on a small subset of the Hilbert space basis helps in solving any practical problems. The most straightforward way to make use of the suggested approach is to incorporate it into the the context of variational Monte Carlo. There, one never accesses the complete Hilbert space. At every step of optimization, energy of the trial state and its gradient with respect to the variational parameters are computed based on Monte Carlo sampling. The sign structure thus only needs to be optimized on small set of nodes of the auxiliary Ising model that scales as $\mathcal{O}(N)$ with the size of the quantum system (see Supplemental Information for the detailed explanation). Using the variational representation to only encode amplitudes and having explicit representation for the signs of the relevant basis vectors, one can hybridize the variational optimization of the amplitude structure with greedy or combinatorial sign optimization. Since the greedy algorithm is log-linear in time, complexity of the sign structure optimization step within the variational loop then scales as $\mathcal{O}(N^4\log N)$ with the number of quantum spins if one is using the second-order extensions, as shown in Supplemental Information. Although the implementation of the complete algorithm goes beyond the scope of this paper, in Supplemental Information we describe it in detail, and explain why nuances such as the necessity of optimization of disconnected clusters, possibly large number of relevant vectors, as well as noise unavoidable in stochastic approaches, do not diminish the applicability of this approach.

In particular, if successfully implemented, the combinatorial approach to sign reconstruction could aid the optimization of NQS representations.  Since the signs can be bootstrapped directly from the amplitudes, they would not need to be encoded in a neural network at all, and the typical issues with learning the sign structure, such as the sign structure generalization problem~\cite{sign_generalization}, simply would not arise. For example, it is instructive to compare the quality of sign structures obtained from mapping on the auxiliary Ising model with what has been achieved by training simple dense neural networks in a conceptually similar setting~\cite{sign_generalization} (exactly known amplitudes, optimization of signs). In the current approach, for the 36-site Kagome lattice, we routinely get partial sign overlap of above $90\%$. In the prior studies~\cite{sign_generalization}, for the 30-site Kagome lattice, the neural networks could not even reach a $40\%$ sign overlap. Moreover, here we sample clusters from a nearly uniform probability distribution $p(i) \sim |\psi^i|^{1/10}$ to ensure that signs of basis vectors with both large and small amplitudes are reconstructed correctly (see the Methods section). The NQS, on the other hand, fails to properly learn even the signs of the ``dominant'' basis vectors with large amplitudes sampled from $p(i) \sim |\psi_i|^2$.

There are a few directions in which our work can be extended. We outline the ideas, but leave the implementation for future studies because we would like to keep the focus of the current paper on the introduced concepts. First of all, the way we treat the sign structures on the extended clusters is suboptimal. For instance, we make the simplest possible approximation that the magnetic field values at the boundary of the extensions are $h_n=0$. However, one can think of designing a non-trivial self-consistent approximation for them, somewhat in the spirit of Dynamical Mean Field Theory~\cite{DMFT} that would systematically improve the local sign structure by iterative adjustment of $h_n$. Besides that, although the classical greedy algorithm is extremely fast, the combinatorial optimization might lead to more accurate results. Since it is much more time consuming, one can think of making it more efficient by executing it on hardware quantum annealers~\cite{QA}, and although the extended clusters might be too big for such devices at the moment, there are ways to overcome this limitation~\cite{raymond2022hybrid,okada2019improving}.

In this paper, we have focused on quantum systems with binary sign structures. In general, when the Hamiltonian is complex-valued, the phases can be mapped onto an XY model~\cite{XY_model} as shown in Supplemental Information. Finally, although we have studied only the ground states, the techniques are applicable to other problems for which a variational principle can be formulated. Searching for excited states~\cite{excited} and simulating the time evolution~\cite{TDVP} of a wave function are two examples.

\section{Methods}

In this paper, we used exact ground state wave functions for quantum spin systems of up to 36 sites as the ground truth reference states, which we obtained with the SpinED package~\cite{SpinED}.

For systems of 16 or 18 spins, we determined the coefficients of the Ising model~\eqref{eq:Ising} and ran both SA and the greedy algorithm on the full Hilbert space graph to optimize the sign structure.
The parameters of the SA algorithm are provided in Supplemental Information.
The greedy algorithm is outlined in this section.

For larger systems of 32--36 spins, we first sampled small connected clusters $\mathcal{C}$ of around 100--1000 basis vectors, constructed their Hamiltonian extensions $\mathcal{C}^{(1)}$ and $\mathcal{C}^{(2)}$, and ran the greedy algorithm to optimize the signs on the extensions.
Some results of running the SA algorithm are provided for comparison in Supplemental Information.

\subsection{Constructing small connected clusters within large Ising graphs}

To analyze whether the ground state sign structures were amenable to local optimization, we performed simulations on systems that have a large Hilbert space, but could still be diagonalized exactly. For each system, we have studied how well the greedy algorithm was able to predict the signs on random connected clusters.

The clusters were constructed by choosing a random starting point and then extending the cluster until it reached the desired size. The initial points were obtained by direct sampling from $|\psi|^{1/10}$. This ensured that basis states with both high and low amplitudes were covered, but zero amplitudes (up to numerical noise) were not considered since even ED might not be accurate around those points. Figure~\ref{alg:random-cluster} shows how the initial cluster was extended until it reached the required size.

% \normalem
\begin{algorithm}[H]\label{alg:random-cluster}
    \small
    \DontPrintSemicolon
    \KwData{$x$---initial point around which the cluster is built;
            $N$---size of the cluster; \ \ $p$---probability of keeping a site;
            $\mathcal{J}_{ij}$---couplings of the auxiliary Ising model.}
    \KwResult{Connected cluster $\mathcal{C}$ of size $N$.}
        $\mathcal{C} \longleftarrow \{ x \}$\;
    \While{$\# \mathcal{C} < N$}{
        $js \longleftarrow \{ j \;|\; \mathcal{J}_{ij} \neq 0, \text{ where } i \in \mathcal{C},\; j \in \mathcal{H} \}$ \;
        \For{$j \in js$}{
            $u \longleftarrow \mathrm{Uniform}(0, 1)$\;
            \If{$u < p$}{
                $\mathcal{C} \longleftarrow \mathcal{C} \cup \{ j \}$\;
                \If{$\# \mathcal{C} = N$}{\textbf{break}\;}
            }
        }
    }
    \vspace{10pt}
\caption{Create a random cluster around the specified point $x$. In all our simulations, the parameter $p$ was set to $1/2$.}
\end{algorithm}
% \ULforem

With the cluster $\mathcal{C}$ at hand, we ran the greedy algorithm on it as well as on its Hamiltonian extensions $\mathcal{C}^{(1)}$ and $\mathcal{C}^{(2)}$ to predict the wave function signs on $\mathcal{C}$. The overlap with the exact ground state, computed on the basis vectors belonging to the cluster, was used to measure the quality of our optimization procedure.

\SideFigure{0.55\textwidth}{0pt}{0.4\textwidth}{\includegraphics[width=0.65\columnwidth]{handmade/greedy_new.pdf}%
}{The idea of the greedy algorithm. The greedy algorithm first locally optimizes signs connected by strongest couplings.%
}{fig:greedy}

\subsection{Deterministic greedy algorithm for signs reconstruction}

In this section we describe the greedy algorithm for sign structure optimization on a connected sub-graph $G$ of the Ising model, where $G$ can span the entire Hilbert space or a $\mathcal{C}^{(n)}$ extension of some cluster of interest. Each edge $k$ of the graph is a tuple $(i_k, j_k, \mathcal{J}_{i_k, j_k})$ where $i_k$ and $j_k$ are indices of Ising spins connected by the edge $k$.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{handmade/greedy_steps_new.pdf}%width=1\columnwidth]
    \caption{\textbf{Possible decisions the greedy algorithm makes at every step depending on the states of sites and configurations of already scanned clusters.} Yellow nodes and orange edges belong to $G'$ graph that is being constructed during the algorithm evaluation time.}
    \label{fig:greedy_steps}
\end{figure}
    
The idea is to try to minimize the local energies of the strongest edges, Fig. \ref{fig:greedy}. We iterate over edges in decreasing order of their $|\mathcal{J}_{i_k,j_k}|$ and add them to an initially empty graph $G'$. In other words, all nodes in $G'$ have their signs assigned and all nodes in $G \setminus G'$---not yet. For each edge, we use the following heuristic for choosing the signs:

\begin{itemize}[topsep=0pt, noitemsep]
    \item If both $i_k$ and $j_k$ are in $G\setminus G'$ (i.e.,  do not yet have signs), we choose $\mathcal{S}_{i_k}$ and $\mathcal{S}_{j_k}$ such that the energy is minimized, or, in other words, such that $\mathcal{J}_{i_k,j_k} \mathcal{S}_{i_k} \mathcal{S}_{j_k} < 0$ (See Fig.~\ref{fig:greedy_steps}~a)).
    
    \item If only one of the signs, say, $\mathcal{S}_{i_k}$ is already assigned, we choose $\mathcal{S}_{j_k}$ to minimize the energy, i.e. such that
    \begin{equation*}
        \mathcal{S}_{j_k}
            \sum_{i_n} \mathcal{S}_{i_n} \mathcal{J}_{i_n,j_k} < 0
    \end{equation*}
    where the sum runs only over $i_n$ that belong to the same connected component of $G'$. Note that edges $(i_n, j_k, \mathcal{J}_{i_n, j_k})$ do not yet belong to $G'$ (See Fig.~\ref{fig:greedy_steps}~b)).

    \item If both signs are assigned and belong to the same connected component of $G'$, we do nothing (See Fig.~\ref{fig:greedy_steps}~c)).    
    
    Motivation: Since we process edges in the decreasing order of their coupling strengths, the coupling $\mathcal{J}_{i_k, j_k}$ cannot be stronger than any of the couplings in the connected component. Hence, even the edge turns out to be frustrated, it should not be optimized as flipping the sign of either $i_k$ or $j_k$ would increase the energy of the part of the Ising model that we have already processed.
    
    \item If both signs are assigned and belong to different connected components of $G'$, we merge the two components flipping, if necessary, all signs in the second one (when $\mathcal{S}_{i_k} \mathcal{S}_{j_k} \mathcal{J}_{i_k,j_k} > 0$). This again minimizes the energy of the already processed part of the Ising model (See Fig.~\ref{fig:greedy_steps}~d)).
\end{itemize}

\section{Additional resources}

\QRListItem{https://journals.aps.org/prb/supplemental/10.1103/PhysRevB.106.L041104/02_supplement.pdf}{Supplemental information containing additional numerical data for other cluster sizes.}
\QRListItem{https://github.com/twesterhout/ising-glass-annealer}{Haskell implementation of the Simulated Annealing and greedy algorithms used in this chapter. The code is available on GitHub.}
\QRListItem{https://doi.org/10.5281/zenodo.8221179}{Zenodo dataset with the code to carry out the simulations and data to reproduce all figures from this chapter. Figures can be re-generated by running \texttt{nix build github:twesterhout/phd-thesis\#Commun\_Phys\_6\_275\_2023}.}
